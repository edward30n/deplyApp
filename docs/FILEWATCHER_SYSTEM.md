# FileWatcher System - Documentaci√≥n T√©cnica

## üìã Descripci√≥n General

El FileWatcher es un sistema de monitoreo autom√°tico que detecta archivos CSV cargados en la carpeta `uploads/csv/raw` y los procesa autom√°ticamente utilizando algoritmos de machine learning para generar archivos JSON optimizados.

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FILEWATCHER ARCHITECTURE                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  üìÅ uploads/csv/raw/         üîç FileWatcher Monitor             ‚îÇ
‚îÇ  ‚îú‚îÄ archivo1.csv           ‚îú‚îÄ Polling cada 2s                  ‚îÇ
‚îÇ  ‚îú‚îÄ archivo2.csv           ‚îú‚îÄ Detecta nuevos CSV               ‚îÇ
‚îÇ  ‚îî‚îÄ archivo3.csv           ‚îî‚îÄ Trigger procesamiento             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ü§ñ CSV Processor           üìä ML Algorithms                    ‚îÇ
‚îÇ  ‚îú‚îÄ Validar CSV            ‚îú‚îÄ pandas + numpy                   ‚îÇ
‚îÇ  ‚îú‚îÄ Procesar datos         ‚îú‚îÄ scipy + scikit-learn             ‚îÇ
‚îÇ  ‚îî‚îÄ Generar JSON           ‚îî‚îÄ Algoritmos de rutas              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  üì§ Output Generation       üóÇÔ∏è File Organization               ‚îÇ
‚îÇ  ‚îú‚îÄ uploads/json/output/    ‚îú‚îÄ CSV ‚Üí processed/                ‚îÇ
‚îÇ  ‚îú‚îÄ uploads/json/storage/   ‚îú‚îÄ JSON r√°pido ‚Üí output/           ‚îÇ
‚îÇ  ‚îî‚îÄ Archivos hist√≥ricos    ‚îî‚îÄ JSON hist√≥rico ‚Üí storage/        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß Configuraci√≥n

### Variables de Entorno
```env
ENABLE_FILE_WATCHER=true     # Habilita el FileWatcher
CSV_RAW_DIR=uploads/csv/raw  # Carpeta monitoreada
JSON_OUTPUT_DIR=uploads/json/output
JSON_STORAGE_DIR=uploads/json/storage
CSV_PROCESSED_DIR=uploads/csv/processed
```

### Configuraci√≥n de Azure
En el workflow de deployment (`azure-backend-deploy.yml`):
```yaml
echo "ENABLE_FILE_WATCHER=true" >> .env
```

## üìÅ Estructura de Directorios

```
backend/uploads/
‚îú‚îÄ‚îÄ csv/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # üì• CSV cargados (monitoreados)
‚îÇ   ‚îî‚îÄ‚îÄ processed/           # ‚úÖ CSV procesados (archivo)
‚îú‚îÄ‚îÄ json/
‚îÇ   ‚îú‚îÄ‚îÄ output/              # üöÄ JSON r√°pido (sobrescrito)
‚îÇ   ‚îî‚îÄ‚îÄ storage/             # üìö JSON hist√≥rico (permanente)
‚îî‚îÄ‚îÄ logs/                    # üìù Logs de procesamiento
```

## üîç Funcionamiento del FileWatcher

### 1. Inicializaci√≥n
```python
# app/main.py
if start_file_watcher():
    logger.info("‚úÖ File Watcher iniciado correctamente")
else:
    logger.warning("‚ö†Ô∏è No se pudo iniciar el File Watcher")
```

### 2. Monitoreo Continuo
- **Frecuencia**: Polling cada 2 segundos
- **Archivos**: Detecta archivos `.csv` en `uploads/csv/raw/`
- **Filtros**: Solo procesa archivos nuevos (no procesados)

### 3. Procesamiento Autom√°tico
```python
def run_process(nombre):
    try:
        print("[PROCESS] Iniciando procesamiento de:", nombre)
        from app.services.processing.csv_processor import csv_processor
        resultado = csv_processor.procesar_archivo_especifico(Path(nombre).name)
        print("[PROCESS] Resultado segmentos:", len(resultado))
    except Exception as e:
        print("[PROCESS][ERROR]", e)
```

### 4. Generaci√≥n de Archivos
- **JSON Output**: `datosRecWay_output.json` (sobrescrito)
- **JSON Storage**: `datosRecWay_{archivo}_{timestamp}.json` (hist√≥rico)
- **CSV Procesado**: Movido a `uploads/csv/processed/`

## üìä Flujo de Procesamiento

### Paso 1: Detecci√≥n
```
[FILEWATCHER] Nuevo archivo detectado: ejemplo.csv
[FILEWATCHER] Tama√±o: 1.2 MB
[FILEWATCHER] Iniciando procesamiento...
```

### Paso 2: Validaci√≥n
- Verificar extensi√≥n `.csv`
- Validar estructura de datos
- Comprobar formato de coordenadas

### Paso 3: Procesamiento ML
- Carga de datos con pandas
- Aplicaci√≥n de algoritmos de rutas
- Segmentaci√≥n geogr√°fica
- Optimizaci√≥n de trayectorias

### Paso 4: Generaci√≥n de Output
- JSON optimizado para frontend
- Archivo hist√≥rico para auditor√≠a
- Movimiento de CSV a carpeta procesados

### Paso 5: Notificaci√≥n
```
[PROCESS] Resultado segmentos: 1247
[FILEWATCHER] Procesamiento completado exitosamente
[FILEWATCHER] Archivo movido a processed/
```

## üîß Configuraci√≥n de Producci√≥n

### Gunicorn Settings
```bash
# Configurado para manejar FileWatcher
gunicorn -k uvicorn.workers.UvicornWorker -w 1 -t 120 -b 0.0.0.0:8000 app.main:app
```

### Memory Management
- **Plan**: P1v2 (3.5 GB RAM)
- **Workers**: 1 worker (evita competencia por memoria)
- **Timeout**: 120s para procesamiento completo

### Monitoreo
```python
def get_file_watcher_status():
    """Estado del file watcher con estad√≠sticas"""
    return {
        "active": _file_watcher.is_active,
        "files_processed": _file_watcher.processed_count,
        "last_activity": _file_watcher.last_activity,
        "watch_folder": str(_file_watcher.watch_folder)
    }
```

## üö® Troubleshooting

### Problema: FileWatcher no inicia
**S√≠ntomas**: Log muestra "‚ö†Ô∏è No se pudo iniciar el File Watcher"
**Soluci√≥n**: 
1. Verificar `ENABLE_FILE_WATCHER=true`
2. Comprobar permisos de directorio
3. Revisar logs de Azure

### Problema: Archivos no se procesan
**S√≠ntomas**: CSV en raw/ pero no hay JSON generado
**Soluci√≥n**:
1. Verificar formato CSV v√°lido
2. Comprobar memoria disponible
3. Revisar logs de procesamiento

### Problema: Memory errors
**S√≠ntomas**: SIGKILL o Worker timeout
**Soluci√≥n**:
1. Ya resuelto con plan P1v2
2. Reducir workers a 1
3. Aumentar timeout si necesario

## üìù Logs y Monitoreo

### Logs de FileWatcher
```bash
# Ver logs en tiempo real
az webapp log tail --name recway-backend-central --resource-group recway-central-rg

# Buscar logs espec√≠ficos
grep "FILEWATCHER" /home/LogFiles/application.log
grep "PROCESS" /home/LogFiles/application.log
```

### Endpoints de Monitoreo
- **Status**: `GET /api/v1/filewatcher/status`
- **Stats**: `GET /api/v1/filewatcher/stats`
- **Health**: `GET /api/v1/test`

## üîÑ API Integration

### Upload + FileWatcher Flow
1. **Upload**: `POST /api/v1/files/upload-csv`
2. **Background**: FileWatcher detecta autom√°ticamente
3. **Process**: Procesamiento ML autom√°tico
4. **Output**: JSON disponible para frontend

### Sync vs Async
- **Async** (default): Upload + background processing
- **Sync**: Upload + procesamiento inmediato (par√°metro `sync=true`)

## üìà Performance Metrics

### Tiempos T√≠picos
- **Detecci√≥n**: < 2 segundos
- **Validaci√≥n**: < 1 segundo
- **Procesamiento**: 30-120 segundos (seg√∫n tama√±o)
- **Generaci√≥n JSON**: < 5 segundos

### Capacidad
- **Archivos simult√°neos**: 1 (procesamiento secuencial)
- **Tama√±o m√°ximo**: Limitado por memoria (P1v2)
- **Throughput**: ~1 archivo por minuto (archivos grandes)

## üîÆ Mejoras Futuras

1. **Procesamiento paralelo**: M√∫ltiples workers para archivos grandes
2. **Cola de procesamiento**: Redis/Azure Service Bus
3. **Notificaciones**: WebSockets para updates en tiempo real
4. **M√©tricas avanzadas**: Application Insights integration
5. **Escalado autom√°tico**: Auto-scaling basado en carga

---
**√öltima Actualizaci√≥n**: 19 de Septiembre, 2025  
**Estado**: ‚úÖ FUNCIONAL EN PRODUCCI√ìN  
**Plan**: P1v2 con FileWatcher habilitado